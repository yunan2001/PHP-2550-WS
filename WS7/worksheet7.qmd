---
title: "PHP 2550: Worksheet 7"
subtitle: "Due: October 18th at 11:59pm"
format: pdf
editor: visual
---

## Many Analysts Recap

Summarize the data and research question posed to the teams in the paper "Many Analysts, One Data Set". What do you notice about the difference in methodological approaches teams had? How different are the resulting estimated odds ratios? Overall, what do you think about this experiment? (\~2 paragraphs)

In the paper "Many Analysts, One Data Set", researchers applied a crowdsourcing data analysis approach to investigate the same research question: whether soccer referees are more likely to give red cards to dark-skin-toned players than to light-skin-toned players. The dataset covers 2,053 players from the top male leagues in England, Germany, France, and Spain during the 2012-2013 season, along with 3,147 referees they encountered, creating 146,028 player-referee dyads. Key variables included the players’ position, weight, height, and skin tone, and referee data such as country of origin. Additionally, each player-referee dyad provided information on how many games they interacted in, as well as the frequency of yellow and red cards issued to each player. To be noticed, the skin tone ratings, originally coded on a scale from 1 (very light) to 5 (very dark), were later standardized to a 0 to 1 scale. Additional control variables like age, club, and league which would change over players’ career are received at the time of data collection but not at the times the red cards are awarded. The same dataset was assigned to 29 independent research teams working from 13 different counties and came from various disciplinary backgrounds to investigate the same research questions. Teams are free to decide which variables they would like to include, their statistical methods to use, and their methods to handle nonindependence of players and referees. Among the 29 teams, 21 unique combinations of covariates were used, with some groups including a variety of control variables while others only used a few key variables. Additionally, statistical methods vary as well. Six teams chose to use poisson models, fifteen chose logistic models, six used linear models, and the remaining two teams used specialized methods which are classified as “miscellaneous.” Also, groups chose various methods to address the nonindependence between players and referees, including introducing fixed effects, variance components, and adding clustered standard errors.

The resulting estimated odds ratio varies among teams  significantly, ranging from 0.89 to 2.93, and the median estimate is 1.31. Among the 29 teams, 20 found significant positive  relationships between players’ skin tone and red card issuance, other groups resulted in insignificance with no group resulting in significant negative relationship. Logistic and Poisson models generally produced higher odds ratios, with most teams finding significant effects (median ORs around 1.34–1.36), while linear models showed lower median ORs (1.21) and fewer significant results. Methods to handle nonindependence, such as fixed effects or clustered standard errors, also influenced outcomes, with teams using these methods reporting median ORs from 1.28 to 1.39. These significance variations imply how differences in variable selection and statistical model or approach would lead to various conclusions. This study introduces a really innovative approach for us to show how research is influenced by researchers’ decisions and subjective choices. Even with identical dataset, different researchers could report significant various conclusions due to different choices of variables and statistical methods or analytic approaches. The paper mentions that “in some cases, authors use a particular analytic strategy because it is the one they know how to use, rather than because they have a specific rationale for using it.” This sentence does inspire us about a human side of research that we have never realized before. It implies the hidden subjective choices and personal limitations that can shape the results. By employing a crowdsourced data analysis approach, this study incorporates diverse analytic strategies and perspectives from researchers worldwide, each with unique disciplinary backgrounds. This diversity encourages transparency, highlighting the flexibility in data interpretation and strengthening the robustness and reliability of their results. The collective approach in this study implies benefits of open collaboration, as it enriches our understanding of data by drawing from a wide range of analytic viewpoints. 


## Answering Scientific Questions with Regression

Answer the following questions about the difference-in-differences paper you were assigned. (\~1 paragraph per question)

1.  What was the motivating research question? How was this translated to a scientific question and analytic approach?

2.  What is the underlying model(s) used? Be as specific as possible and explain how you determined the model.

3.  How were the results used to answer the question and what was the conclusion?

4.  Overall, how do you evaluate this paper? Think about strengths and weaknesses of the approach and any remaining questions you have.

## Model Evaluation Example

These questions are on the paper 'Predicting lung cancer prior to surgical resection in patients with lung nodules' by Deppen et al. This paper introduces a model called TREAT that is currently used in practice to predict lung cancer.

1.  Compare the Mayo model to the TREAT model in terms of the initial goals of building the model, the population the training data represented, the variables included, and the resulting model. (\~2 paragraphs)

2.  What measures or visuals were used to evaluate the models? How do we interpret these? Why do you think these measures were chosen for comparison? (1 paragraph)

3.  What were some limitations that the paper addressed? (1 paragraph)

## Model Building Practice

Read the [NEJM editorial](https://www.nejm.org/doi/full/10.1056/NEJMe2114918) to understand the background of developing the equations that are used to calculate the estimated glomerular filtration rate (eGFR). Then, load in the data `baseseg.csv` and run the pre-processing below. The data contains the following variables.

1.  Base serum Creatinine (bascre)

2.  Systolic blood pressure (sbase)

3.  Diastolic blood pressure (dbase)

4.  Urine protein (baseu)

5.  Age (age)

6.  Sex (Sex = 1 if male; = 0 if female)

7.  Indicator if African-American (black)

8.  Measured glomerular filtration rate (gfr)

In this worksheet, we will build a model to calculate the eGFR and practice our model evaluation skills.

1.  Conduct a brief exploratory data analysis (EDA). Check the distributions of the variables and consider whether transformations are necessary. Hints: Log transformations or polynomial transformations may be helpful.

2.  Build a linear regression model with appropriate variable selection. Check the model assumptions using model diagnostics. You may also consider including interaction terms.

3.  Evaluate the performance of the model using evaluation measures. Using your evaluation and your estimated model, comment on how you useful you expect the model to be in practice.

4.  Evaluate the performance of the model now between race populations. In particular, compare the measured and estimated GFR using mean squared error (MSE), bias, and the percentage of estimates within 10% and 30% of the measured GFR ($P_{10}$ (%) and $P_{30}$ (%), respectively). Visualize the comparison of the measured and estimated GFR.

5.  Repeat steps 1-4 but remove the race variable (black) from consideration. Interpret your results and relate them back to the discussion in the editorial.

6.  Last, write a non-technical summary of one of your models and its evaluation (1 paragraph) for a clinical audience.

```{r}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(moments))
suppressPackageStartupMessages(library(stats))
suppressPackageStartupMessages(library(kableExtra))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(gtsummary))
suppressPackageStartupMessages(library(corrplot))
suppressPackageStartupMessages(library(ggcorrplot))

kidney_df <- read.csv("baseseg.csv")
kidney_df <- kidney_df %>% 
  select(c(gfr, bascre, sbase, dbase, baseu, AGE, SEX, black)) %>%
  rename(sex = SEX, age = AGE) %>%
  na.omit()
kidney_df$black <- as.factor(kidney_df$black)
kidney_df$sex <- as.factor(kidney_df$sex)
```
 
```{r}
par(mfrow = c(2, 3))
hist(kidney_df$gfr, main = "Distribution of gfr", xlab = "gfr", col = "lightblue")
hist(kidney_df$bascre, main = "Distribution of bascre", xlab = "bascre", col = "lightblue")
hist(kidney_df$sbase, main = "Distribution of sbase", xlab = "sbase", col = "lightblue")
hist(kidney_df$dbase, main = "Distribution of dbase", xlab = "dbase", col = "lightblue")
hist(kidney_df$baseu, main = "Distribution of baseu", xlab = "baseu", col = "lightblue")
hist(kidney_df$age, main = "Distribution of age", xlab = "age", col = "lightblue")

# Calculate skewness
skewness_value <- skewness(kidney_df[, 1:6])
knitr::kable(skewness_value,
             caption = "Variable Skewness Value",
             col.names = c("Variable", "Skewness")) %>%
      kable_styling(latex_options = "HOLD_position")

kidney_df$log_bascre <- log(kidney_df$bascre)
kidney_df$log_baseu <- ifelse(kidney_df$baseu <= 0.1, kidney_df$baseu, log(kidney_df$baseu))
kidney_df$sqrt_gfr <- sqrt(kidney_df$gfr)
kidney_df$log_gfr <- log(kidney_df$gfr)

par(mfrow = c(2, 2))
hist(kidney_df$log_bascre, main = "Distribution of log_bascre", xlab = "Log Transformed gfr", col = "lightblue")
hist(kidney_df$log_baseu, main = "Distribution of log_baseu", xlab = "Log Transformed baseu", col = "lightblue")
hist(kidney_df$log_gfr, main = "Distribution of log_gfr", xlab = "Log Transformed gfr", col = "lightblue")
hist(kidney_df$sqrt_gfr, main = "Distribution of sqrt_gfr", xlab = "Square Root gfr", col = "lightblue")
```

```{r}
kidney_tbl <- kidney_df %>%
  mutate(black = recode(black, `0` = "Non-Black", `1` ="Black"),
         sex = recode(sex, `0` = "Female", `1` ="Male")) %>%
  tbl_summary(by=black,
              label = list(gfr ~ "Measured glomerular filtration rate",
                           bascre ~ "Base serum Creatinine",
                           sbase ~ "Systolic blood pressure",
                           dbase ~ " Diastolic blood pressure",
                           baseu ~ "Urine protein"
                           ),
              statistic = all_continuous() ~ "{mean} ({sd})") %>%
  modify_spanning_header(update =  all_stat_cols() ~  "**Black**") %>%
  modify_footnote(update = all_stat_cols() ~ "Mean (SD) for continuous; n (%) for categorical") %>%
  bold_labels()
kidney_tbl
```

```{r}
cor_m <-cor(kidney_df[, -c(1, 2, 5, 7, 8)])
variable_order <- c("log_baseu", "log_bascre", "dbase", "sbase", "age", "sqrt_gfr", "log_gfr")
r_reordered <- cor_m[variable_order, variable_order]

ggcorrplot(r_reordered, 
           hc.order = TRUE, 
           type = "lower",
           lab = TRUE) +
  ggtitle("Figure 2: Correlation Matrix") +
  theme(plot.title = element_text(hjust = 0.5, size=14),
        axis.text.x = element_text(size = 12),             
        axis.text.y = element_text(size = 12))
```


```{r}
model_log <- lm(log_gfr ~ log_bascre + sbase + dbase + log_baseu + age + sex + black, data = kidney_df)

summary(model_log)

model_sqrt <- lm(sqrt_gfr ~ log_bascre + sbase + dbase + log_baseu + age + sex + black, data = kidney_df)

summary(model_sqrt)

# QQ plot for normality check
qqnorm(resid(model_log), main = "QQ Plot for log(GFR)")
qqline(resid(model_log), col = "red")

qqnorm(resid(model_sqrt), main = "QQ Plot for sqrt(GFR)")
qqline(resid(model_sqrt), col = "red")

AIC(model_log, model_sqrt)
BIC(model_log, model_sqrt)
```

